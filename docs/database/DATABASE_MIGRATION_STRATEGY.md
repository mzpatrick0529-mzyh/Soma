# ğŸ—„ï¸ Soma æ•°æ®åº“è¿ç§»æˆ˜ç•¥

## ğŸ“Š ç°çŠ¶åˆ†æ

### å½“å‰æ¶æ„
- **æ•°æ®åº“**: SQLite (æœ¬åœ°æ–‡ä»¶ `self_agent.db`)
- **å­˜å‚¨æ–¹å¼**: æœ¬åœ°ç£ç›˜å­˜å‚¨
- **é—®é¢˜**:
  - âŒ æœ¬åœ°ç©ºé—´ä¸è¶³
  - âŒ æ— å¤‡ä»½/å®¹ç¾æœºåˆ¶
  - âŒ æ— æ³•æ¨ªå‘æ‰©å±•
  - âŒ å•ç‚¹æ•…éšœé£é™©
  - âŒ æ— å¤šç§Ÿæˆ·éš”ç¦»
  - âŒ å‘é‡æ£€ç´¢æ€§èƒ½å—é™

### æ•°æ®è§„æ¨¡é¢„ä¼°
```
æ¯ç”¨æˆ·æ•°æ®é‡:
- æ–‡æ¡£: 1,000 - 10,000 ä¸ª
- Chunks: 10,000 - 100,000 ä¸ª
- å‘é‡ (768ç»´): 10,000 - 100,000 ä¸ª Ã— 3KB â‰ˆ 30MB - 300MB
- æ€»è®¡: 50MB - 500MB/ç”¨æˆ·

100ç”¨æˆ·: 5GB - 50GB
1,000ç”¨æˆ·: 50GB - 500GB
10,000ç”¨æˆ·: 500GB - 5TB
```

---

## ğŸ¯ è§£å†³æ–¹æ¡ˆæ¶æ„

### æ ¸å¿ƒéœ€æ±‚
1. âœ… **ç»å¯¹å®‰å…¨**: ç«¯åˆ°ç«¯åŠ å¯† (E2EE)
2. âœ… **éšç§ä¿æŠ¤**: ç”¨æˆ·æ•°æ®éš”ç¦»ã€GDPR/CCPAåˆè§„
3. âœ… **æ–¹ä¾¿RAG**: é«˜æ€§èƒ½å‘é‡æ£€ç´¢
4. âœ… **æ”¯æŒå¾®è°ƒ**: ç»“æ„åŒ–æ•°æ®å¯¼å‡º
5. âœ… **MVPå…è´¹**: å¯åŠ¨é˜¶æ®µé›¶æˆæœ¬
6. âœ… **å¯æ‰©å±•**: å•†ä¸šåŒ–å¹³æ»‘å‡çº§

---

## ğŸš€ MVPæ–¹æ¡ˆï¼šSupabase (å…è´¹å±‚)

### ä¸ºä»€ä¹ˆé€‰æ‹©Supabaseï¼Ÿ

#### âœ… ä¼˜åŠ¿
1. **å®Œå…¨å…è´¹å¯åŠ¨**
   - 500MB PostgreSQLæ•°æ®åº“
   - 1GBæ–‡ä»¶å­˜å‚¨ (Supabase Storage)
   - 50,000 æ¬¡/æœˆæ´»è·ƒç”¨æˆ·
   - 2GBæ•°æ®ä¼ è¾“/æœˆ
   - æ— éœ€ä¿¡ç”¨å¡

2. **åŸç”Ÿå‘é‡æ”¯æŒ**
   - pgvectoræ‰©å±• (å¼€ç®±å³ç”¨)
   - æ”¯æŒä½™å¼¦ç›¸ä¼¼åº¦ã€L2è·ç¦»ã€å†…ç§¯
   - ç´¢å¼•ä¼˜åŒ– (HNSW, IVFFlat)

3. **å®‰å…¨æ€§**
   - Row Level Security (RLS) - æ•°æ®åº“çº§éš”ç¦»
   - SSL/TLSåŠ å¯†ä¼ è¾“
   - è‡ªåŠ¨å¤‡ä»½
   - ç¬¦åˆSOC 2 Type 2, ISO 27001

4. **éšç§åˆè§„**
   - EUæ•°æ®ä¸­å¿ƒé€‰é¡¹ (GDPR)
   - æ•°æ®æ®‹ç•™æƒã€è¢«é—å¿˜æƒæ”¯æŒ
   - Audit logs

5. **å¼€å‘è€…å‹å¥½**
   - RESTful APIè‡ªåŠ¨ç”Ÿæˆ
   - Real-time subscriptions
   - TypeScript SDK
   - ä¸ç°æœ‰SQLite schemaå…¼å®¹åº¦é«˜

#### âš ï¸ é™åˆ¶ (å…è´¹å±‚)
- 500MBæ•°æ®åº“ â‰ˆ æ”¯æŒ10-50ä¸ªé‡åº¦ç”¨æˆ·
- æ— è‡ªåŠ¨å¤‡ä»½ (éœ€æ‰‹åŠ¨å¯¼å‡º)
- æš‚åœç­–ç•¥: 7å¤©æ— æ´»åŠ¨ä¼šæš‚åœé¡¹ç›®

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Soma Frontend                        â”‚
â”‚                    (React + TypeScript)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Soma Self AI Agent                       â”‚
â”‚                   (Node.js + Express)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Database Adapter Layer                  â”‚   â”‚
â”‚  â”‚  - æŠ½è±¡åŒ–æ•°æ®åº“æ“ä½œ                                    â”‚   â”‚
â”‚  â”‚  - æ”¯æŒ SQLite (æœ¬åœ°) / Supabase (äº‘ç«¯)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite     â”‚          â”‚    Supabase      â”‚
â”‚  (å¼€å‘/æµ‹è¯•)  â”‚          â”‚   (ç”Ÿäº§/MVP)      â”‚
â”‚              â”‚          â”‚                  â”‚
â”‚ - æœ¬åœ°å¼€å‘    â”‚          â”‚ - PostgreSQL     â”‚
â”‚ - å•å…ƒæµ‹è¯•    â”‚          â”‚ - pgvector       â”‚
â”‚ - ç¦»çº¿æ¨¡å¼    â”‚          â”‚ - RLSå®‰å…¨        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ - è‡ªåŠ¨å¤‡ä»½        â”‚
                          â”‚ - Real-time      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®åŠ å¯†ç­–ç•¥

#### 1. ä¼ è¾“åŠ å¯† (In-Transit)
```
Client â†’ TLS 1.3 â†’ Soma Backend â†’ TLS 1.3 â†’ Supabase
```

#### 2. å­˜å‚¨åŠ å¯† (At-Rest)
```typescript
// æ•æ„Ÿå­—æ®µå®¢æˆ·ç«¯åŠ å¯†
import { createCipheriv, createDecipheriv, randomBytes } from 'crypto';

class E2EEService {
  // ç”¨æˆ·ä¸»å¯†é’¥ (æ´¾ç”Ÿè‡ªç”¨æˆ·å¯†ç )
  private userMasterKey: Buffer;

  // åŠ å¯†æ–‡æ¡£å†…å®¹
  encryptContent(plaintext: string): {
    encrypted: string;
    iv: string;
    authTag: string;
  } {
    const iv = randomBytes(16);
    const cipher = createCipheriv('aes-256-gcm', this.userMasterKey, iv);
    
    let encrypted = cipher.update(plaintext, 'utf8', 'hex');
    encrypted += cipher.final('hex');
    
    const authTag = cipher.getAuthTag().toString('hex');
    
    return {
      encrypted,
      iv: iv.toString('hex'),
      authTag
    };
  }

  // è§£å¯†æ–‡æ¡£å†…å®¹
  decryptContent(encrypted: string, iv: string, authTag: string): string {
    const decipher = createDecipheriv(
      'aes-256-gcm',
      this.userMasterKey,
      Buffer.from(iv, 'hex')
    );
    
    decipher.setAuthTag(Buffer.from(authTag, 'hex'));
    
    let decrypted = decipher.update(encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    
    return decrypted;
  }
}
```

#### 3. é›¶çŸ¥è¯†è¯æ˜æ¶æ„
```
ç”¨æˆ·å¯†ç  â†’ PBKDF2 (100,000 rounds) â†’ Master Key
                                      â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                             â”‚
                     Encryption Key            Authentication Key
                    (åŠ å¯†æ•°æ®å†…å®¹)                (Supabaseç™»å½•)
                        â†“                             â†“
                   AES-256-GCM                    å­˜å‚¨åˆ°Supabase
                  (å®¢æˆ·ç«¯åŠ å¯†)                   (ç”¨äºRow-Level Security)
```

**å…³é”®**: Supabaseåªå­˜å‚¨åŠ å¯†åçš„æ•°æ®ï¼Œæ— æ³•è¯»å–æ˜æ–‡ã€‚

---

## ğŸ“‹ å®æ–½æ­¥éª¤ï¼ˆMVPï¼‰

### Phase 1: ç¯å¢ƒå‡†å¤‡ (30åˆ†é’Ÿ)

#### Step 1.1: åˆ›å»ºSupabaseé¡¹ç›®
```bash
# 1. è®¿é—® https://supabase.com
# 2. æ³¨å†Œ/ç™»å½•è´¦å·
# 3. ç‚¹å‡» "New Project"
# 4. å¡«å†™:
#    - Name: soma-mvp
#    - Database Password: [ç”Ÿæˆå¼ºå¯†ç å¹¶ä¿å­˜]
#    - Region: é€‰æ‹©ç¦»ç”¨æˆ·æœ€è¿‘çš„åŒºåŸŸ
#      * East US (Ohio) - ç¾å›½
#      * West US (Oregon) - ç¾å›½è¥¿æµ·å²¸
#      * Southeast Asia (Singapore) - äºšæ´²
#    - Pricing Plan: Free
# 5. ç‚¹å‡» "Create new project"
# 6. ç­‰å¾…2-3åˆ†é’Ÿåˆå§‹åŒ–
```

#### Step 1.2: è·å–è¿æ¥ä¿¡æ¯
```bash
# åœ¨Supabase Dashboard:
# Settings â†’ Database â†’ Connection String

# å¤åˆ¶ä»¥ä¸‹ä¿¡æ¯:
# - Project URL: https://xxxxx.supabase.co
# - anon (public) key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
# - service_role key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
# - Database Password: [ä½ è®¾ç½®çš„å¯†ç ]

# Connection stringæ ¼å¼:
# postgresql://postgres:[YOUR-PASSWORD]@db.xxxxx.supabase.co:5432/postgres
```

#### Step 1.3: å¯ç”¨pgvectoræ‰©å±•
```sql
-- åœ¨Supabase SQL Editorä¸­æ‰§è¡Œ:
-- Database â†’ SQL Editor â†’ New Query

CREATE EXTENSION IF NOT EXISTS vector;

-- éªŒè¯å®‰è£…
SELECT * FROM pg_extension WHERE extname = 'vector';
```

### Phase 2: Schemaè¿ç§» (1å°æ—¶)

#### Step 2.1: åˆ›å»ºSupabase Schema
```sql
-- File: Self_AI_Agent/src/db/supabase_schema.sql

-- ============================================
-- Soma Supabase Schema with E2EE
-- ============================================

-- ç”¨æˆ·è¡¨
CREATE TABLE users (
  id TEXT PRIMARY KEY,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- è®¤è¯ç”¨æˆ· (æ‰©å±•Supabase Auth)
CREATE TABLE auth_users (
  email TEXT PRIMARY KEY,
  name TEXT,
  username TEXT,
  avatar TEXT,
  -- å¯†ç ç”±Supabase Authç®¡ç†ï¼Œä¸å­˜å‚¨åœ¨è¿™é‡Œ
  -- åŠ å¯†å¯†é’¥æ´¾ç”Ÿç›å€¼ (ç”¨äºå®¢æˆ·ç«¯å¯†é’¥ç”Ÿæˆ)
  encryption_salt TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- æ–‡æ¡£è¡¨ (contentåŠ å¯†å­˜å‚¨)
CREATE TABLE documents (
  id TEXT PRIMARY KEY,
  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  source TEXT,
  type TEXT,
  title TEXT, -- æ˜æ–‡å­˜å‚¨ (ç”¨äºæœç´¢)
  -- E2EE åŠ å¯†å­—æ®µ
  encrypted_content TEXT, -- AES-256-GCMåŠ å¯†çš„å†…å®¹
  content_iv TEXT, -- åˆå§‹åŒ–å‘é‡
  content_auth_tag TEXT, -- è®¤è¯æ ‡ç­¾
  metadata JSONB, -- éæ•æ„Ÿå…ƒæ•°æ® (æ˜æ–‡)
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_documents_user ON documents(user_id);
CREATE INDEX idx_documents_source ON documents(source);
CREATE INDEX idx_documents_created ON documents(created_at DESC);

-- Chunksè¡¨ (textåŠ å¯†å­˜å‚¨)
CREATE TABLE chunks (
  id TEXT PRIMARY KEY,
  doc_id TEXT NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  idx INTEGER,
  -- E2EE åŠ å¯†å­—æ®µ
  encrypted_text TEXT,
  text_iv TEXT,
  text_auth_tag TEXT,
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_chunks_user ON chunks(user_id);
CREATE INDEX idx_chunks_doc ON chunks(doc_id);
CREATE INDEX idx_chunks_idx ON chunks(doc_id, idx);

-- å‘é‡è¡¨ (ä½¿ç”¨pgvector)
CREATE TABLE vectors (
  chunk_id TEXT PRIMARY KEY REFERENCES chunks(id) ON DELETE CASCADE,
  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  -- pgvectorç±»å‹ (768ç»´ for sentence-transformers)
  embedding vector(768) NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- å‘é‡ç´¢å¼• (HNSW for fast ANN search)
CREATE INDEX idx_vectors_embedding ON vectors 
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_vectors_user ON vectors(user_id);

-- ç”¨æˆ·ä¸“å±AIæ¨¡å‹
CREATE TABLE user_models (
  user_id TEXT PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE,
  model_id TEXT NOT NULL,
  version TEXT NOT NULL,
  -- E2EE: persona profileåŠ å¯†å­˜å‚¨
  encrypted_metadata TEXT,
  metadata_iv TEXT,
  metadata_auth_tag TEXT,
  status TEXT DEFAULT 'training', -- 'training', 'ready', 'error'
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_user_models_status ON user_models(status);

-- åˆè§„æ—¥å¿— (å®¡è®¡è¿½è¸ª)
CREATE TABLE compliance_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  log_type TEXT NOT NULL, -- 'biometric_consent', 'wechat_disclaimer', etc.
  action TEXT NOT NULL, -- 'granted', 'declined', 'revoked'
  metadata JSONB,
  ip_address INET,
  user_agent TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_compliance_logs_user ON compliance_logs(user_id);
CREATE INDEX idx_compliance_logs_type ON compliance_logs(log_type);
CREATE INDEX idx_compliance_logs_created ON compliance_logs(created_at DESC);

-- ============================================
-- Row-Level Security (RLS) Policies
-- ============================================

-- å¯ç”¨RLS
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE auth_users ENABLE ROW LEVEL SECURITY;
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE chunks ENABLE ROW LEVEL SECURITY;
ALTER TABLE vectors ENABLE ROW LEVEL SECURITY;
ALTER TABLE user_models ENABLE ROW LEVEL SECURITY;
ALTER TABLE compliance_logs ENABLE ROW LEVEL SECURITY;

-- ç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
CREATE POLICY users_policy ON users
  FOR ALL USING (auth.uid()::text = id);

CREATE POLICY auth_users_policy ON auth_users
  FOR ALL USING (auth.uid()::text = email OR auth.email() = email);

CREATE POLICY documents_policy ON documents
  FOR ALL USING (auth.uid()::text = user_id);

CREATE POLICY chunks_policy ON chunks
  FOR ALL USING (auth.uid()::text = user_id);

CREATE POLICY vectors_policy ON vectors
  FOR ALL USING (auth.uid()::text = user_id);

CREATE POLICY user_models_policy ON user_models
  FOR ALL USING (auth.uid()::text = user_id);

CREATE POLICY compliance_logs_policy ON compliance_logs
  FOR ALL USING (auth.uid()::text = user_id);

-- ============================================
-- Functions & Triggers
-- ============================================

-- è‡ªåŠ¨æ›´æ–° updated_at æ—¶é—´æˆ³
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_users_updated_at
  BEFORE UPDATE ON users
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_auth_users_updated_at
  BEFORE UPDATE ON auth_users
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_documents_updated_at
  BEFORE UPDATE ON documents
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_user_models_updated_at
  BEFORE UPDATE ON user_models
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- å‘é‡ç›¸ä¼¼åº¦æœç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION search_similar_chunks(
  query_embedding vector(768),
  query_user_id TEXT,
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 10
)
RETURNS TABLE (
  chunk_id TEXT,
  doc_id TEXT,
  similarity FLOAT,
  encrypted_text TEXT,
  text_iv TEXT,
  text_auth_tag TEXT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    c.id,
    c.doc_id,
    1 - (v.embedding <=> query_embedding) AS similarity,
    c.encrypted_text,
    c.text_iv,
    c.text_auth_tag
  FROM vectors v
  JOIN chunks c ON c.id = v.chunk_id
  WHERE v.user_id = query_user_id
    AND 1 - (v.embedding <=> query_embedding) > match_threshold
  ORDER BY v.embedding <=> query_embedding
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql;

-- ============================================
-- åˆå§‹åŒ–
-- ============================================

-- åˆ›å»ºé»˜è®¤ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_documents_title_trgm ON documents USING gin(title gin_trgm_ops);

COMMENT ON TABLE documents IS 'User documents with E2EE encrypted content';
COMMENT ON TABLE chunks IS 'Document chunks with E2EE encrypted text';
COMMENT ON TABLE vectors IS 'Vector embeddings for semantic search (pgvector)';
COMMENT ON COLUMN documents.encrypted_content IS 'AES-256-GCM encrypted content (client-side encryption)';
COMMENT ON COLUMN chunks.encrypted_text IS 'AES-256-GCM encrypted chunk text';
```

#### Step 2.2: æ‰§è¡ŒSchemaè¿ç§»
```bash
# 1. ä¿å­˜ä¸Šè¿°SQLåˆ°æ–‡ä»¶
cd /Users/patrick_ma/Soma/Soma_V0/Self_AI_Agent

# 2. åœ¨Supabase Dashboardæ‰§è¡Œ
# Database â†’ SQL Editor â†’ New Query
# ç²˜è´´æ•´ä¸ªschemaå¹¶æ‰§è¡Œ

# æˆ–ä½¿ç”¨psqlå‘½ä»¤è¡Œ:
psql "postgresql://postgres:[YOUR-PASSWORD]@db.xxxxx.supabase.co:5432/postgres" \
  -f src/db/supabase_schema.sql
```

### Phase 3: ä»£ç é€‚é… (2-3å°æ—¶)

#### Step 3.1: å®‰è£…ä¾èµ–
```bash
cd /Users/patrick_ma/Soma/Soma_V0/Self_AI_Agent

# Supabaseå®¢æˆ·ç«¯
npm install @supabase/supabase-js

# åŠ å¯†åº“
npm install crypto-js
npm install --save-dev @types/crypto-js

# PostgreSQLé©±åŠ¨ (å¤‡ç”¨)
npm install pg
npm install --save-dev @types/pg
```

#### Step 3.2: åˆ›å»ºæ•°æ®åº“é€‚é…å±‚
```typescript
// File: Self_AI_Agent/src/db/adapter.ts

import { createClient, SupabaseClient } from '@supabase/supabase-js';
import Database from 'better-sqlite3';
import * as crypto from 'crypto';

// æ•°æ®åº“ç±»å‹
export enum DBType {
  SQLITE = 'sqlite',
  SUPABASE = 'supabase'
}

// é…ç½®æ¥å£
export interface DBConfig {
  type: DBType;
  // SQLiteé…ç½®
  filename?: string;
  // Supabaseé…ç½®
  supabaseUrl?: string;
  supabaseKey?: string;
  // åŠ å¯†é…ç½®
  encryptionEnabled?: boolean;
}

// ç»Ÿä¸€æ•°æ®åº“æ¥å£
export interface IDatabase {
  // æ–‡æ¡£æ“ä½œ
  insertDocument(doc: Document): Promise<string>;
  getDocument(id: string, userId: string): Promise<Document | null>;
  listDocuments(userId: string, limit?: number): Promise<Document[]>;
  deleteDocument(id: string, userId: string): Promise<boolean>;

  // Chunkæ“ä½œ
  insertChunk(chunk: Chunk): Promise<string>;
  getChunksByDocument(docId: string, userId: string): Promise<Chunk[]>;
  deleteChunksByDocument(docId: string, userId: string): Promise<number>;

  // å‘é‡æ“ä½œ
  insertVector(vector: Vector): Promise<void>;
  searchSimilarVectors(
    embedding: number[],
    userId: string,
    limit: number,
    threshold?: number
  ): Promise<SimilarChunk[]>;

  // ç”¨æˆ·æ¨¡å‹æ“ä½œ
  getUserModel(userId: string): Promise<UserModel | null>;
  insertUserModel(model: UserModel): Promise<void>;
  updateUserModel(userId: string, updates: Partial<UserModel>): Promise<void>;

  // åˆè§„æ—¥å¿—
  insertComplianceLog(log: ComplianceLog): Promise<void>;
}

// ç±»å‹å®šä¹‰
export interface Document {
  id: string;
  userId: string;
  source?: string;
  type?: string;
  title?: string;
  content: string; // æ˜æ–‡ (ä¼šè¢«åŠ å¯†å­˜å‚¨)
  metadata?: Record<string, any>;
}

export interface Chunk {
  id: string;
  docId: string;
  userId: string;
  idx: number;
  text: string; // æ˜æ–‡ (ä¼šè¢«åŠ å¯†å­˜å‚¨)
  metadata?: Record<string, any>;
}

export interface Vector {
  chunkId: string;
  userId: string;
  embedding: number[]; // 768ç»´å‘é‡
}

export interface SimilarChunk {
  chunkId: string;
  docId: string;
  text: string; // è§£å¯†åçš„æ˜æ–‡
  similarity: number;
}

export interface UserModel {
  userId: string;
  modelId: string;
  version: string;
  metadata: Record<string, any>; // æ˜æ–‡ (ä¼šè¢«åŠ å¯†å­˜å‚¨)
  status: 'training' | 'ready' | 'error';
}

export interface ComplianceLog {
  userId: string;
  logType: string;
  action: string;
  metadata?: Record<string, any>;
  ipAddress?: string;
  userAgent?: string;
}

// ============================================
// Supabaseå®ç° (E2EE + RLS)
// ============================================

export class SupabaseDatabase implements IDatabase {
  private client: SupabaseClient;
  private encryptionEnabled: boolean;
  private userEncryptionKeys: Map<string, Buffer> = new Map();

  constructor(config: DBConfig) {
    if (!config.supabaseUrl || !config.supabaseKey) {
      throw new Error('Supabase URL and Key are required');
    }

    this.client = createClient(config.supabaseUrl, config.supabaseKey);
    this.encryptionEnabled = config.encryptionEnabled ?? true;
  }

  // è®¾ç½®ç”¨æˆ·åŠ å¯†å¯†é’¥ (æ´¾ç”Ÿè‡ªç”¨æˆ·å¯†ç )
  setUserEncryptionKey(userId: string, masterKey: Buffer) {
    this.userEncryptionKeys.set(userId, masterKey);
  }

  // åŠ å¯†æ•°æ®
  private encrypt(plaintext: string, userId: string): {
    encrypted: string;
    iv: string;
    authTag: string;
  } {
    if (!this.encryptionEnabled) {
      return { encrypted: plaintext, iv: '', authTag: '' };
    }

    const key = this.userEncryptionKeys.get(userId);
    if (!key) {
      throw new Error(`Encryption key not set for user ${userId}`);
    }

    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv('aes-256-gcm', key, iv);

    let encrypted = cipher.update(plaintext, 'utf8', 'hex');
    encrypted += cipher.final('hex');

    const authTag = cipher.getAuthTag();

    return {
      encrypted,
      iv: iv.toString('hex'),
      authTag: authTag.toString('hex')
    };
  }

  // è§£å¯†æ•°æ®
  private decrypt(encrypted: string, iv: string, authTag: string, userId: string): string {
    if (!this.encryptionEnabled || !iv || !authTag) {
      return encrypted;
    }

    const key = this.userEncryptionKeys.get(userId);
    if (!key) {
      throw new Error(`Encryption key not set for user ${userId}`);
    }

    const decipher = crypto.createDecipheriv(
      'aes-256-gcm',
      key,
      Buffer.from(iv, 'hex')
    );

    decipher.setAuthTag(Buffer.from(authTag, 'hex'));

    let decrypted = decipher.update(encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');

    return decrypted;
  }

  // æ’å…¥æ–‡æ¡£
  async insertDocument(doc: Document): Promise<string> {
    const { encrypted, iv, authTag } = this.encrypt(doc.content, doc.userId);

    const { data, error } = await this.client
      .from('documents')
      .insert({
        id: doc.id,
        user_id: doc.userId,
        source: doc.source,
        type: doc.type,
        title: doc.title,
        encrypted_content: encrypted,
        content_iv: iv,
        content_auth_tag: authTag,
        metadata: doc.metadata || {}
      })
      .select()
      .single();

    if (error) throw new Error(`Insert document failed: ${error.message}`);
    return data.id;
  }

  // è·å–æ–‡æ¡£
  async getDocument(id: string, userId: string): Promise<Document | null> {
    const { data, error } = await this.client
      .from('documents')
      .select('*')
      .eq('id', id)
      .eq('user_id', userId)
      .single();

    if (error || !data) return null;

    return {
      id: data.id,
      userId: data.user_id,
      source: data.source,
      type: data.type,
      title: data.title,
      content: this.decrypt(
        data.encrypted_content,
        data.content_iv,
        data.content_auth_tag,
        userId
      ),
      metadata: data.metadata
    };
  }

  // åˆ—å‡ºæ–‡æ¡£
  async listDocuments(userId: string, limit: number = 100): Promise<Document[]> {
    const { data, error } = await this.client
      .from('documents')
      .select('*')
      .eq('user_id', userId)
      .order('created_at', { ascending: false })
      .limit(limit);

    if (error) throw new Error(`List documents failed: ${error.message}`);

    return data.map(d => ({
      id: d.id,
      userId: d.user_id,
      source: d.source,
      type: d.type,
      title: d.title,
      content: this.decrypt(
        d.encrypted_content,
        d.content_iv,
        d.content_auth_tag,
        userId
      ),
      metadata: d.metadata
    }));
  }

  // åˆ é™¤æ–‡æ¡£ (çº§è”åˆ é™¤chunkså’Œvectors)
  async deleteDocument(id: string, userId: string): Promise<boolean> {
    const { error } = await this.client
      .from('documents')
      .delete()
      .eq('id', id)
      .eq('user_id', userId);

    return !error;
  }

  // æ’å…¥Chunk
  async insertChunk(chunk: Chunk): Promise<string> {
    const { encrypted, iv, authTag } = this.encrypt(chunk.text, chunk.userId);

    const { data, error } = await this.client
      .from('chunks')
      .insert({
        id: chunk.id,
        doc_id: chunk.docId,
        user_id: chunk.userId,
        idx: chunk.idx,
        encrypted_text: encrypted,
        text_iv: iv,
        text_auth_tag: authTag,
        metadata: chunk.metadata || {}
      })
      .select()
      .single();

    if (error) throw new Error(`Insert chunk failed: ${error.message}`);
    return data.id;
  }

  // è·å–æ–‡æ¡£çš„æ‰€æœ‰Chunks
  async getChunksByDocument(docId: string, userId: string): Promise<Chunk[]> {
    const { data, error } = await this.client
      .from('chunks')
      .select('*')
      .eq('doc_id', docId)
      .eq('user_id', userId)
      .order('idx', { ascending: true });

    if (error) throw new Error(`Get chunks failed: ${error.message}`);

    return data.map(c => ({
      id: c.id,
      docId: c.doc_id,
      userId: c.user_id,
      idx: c.idx,
      text: this.decrypt(
        c.encrypted_text,
        c.text_iv,
        c.text_auth_tag,
        userId
      ),
      metadata: c.metadata
    }));
  }

  // åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰Chunks
  async deleteChunksByDocument(docId: string, userId: string): Promise<number> {
    const { error, count } = await this.client
      .from('chunks')
      .delete()
      .eq('doc_id', docId)
      .eq('user_id', userId);

    if (error) throw new Error(`Delete chunks failed: ${error.message}`);
    return count || 0;
  }

  // æ’å…¥å‘é‡
  async insertVector(vector: Vector): Promise<void> {
    // pgvectoræ ¼å¼: [0.1, 0.2, ...]
    const { error } = await this.client
      .from('vectors')
      .insert({
        chunk_id: vector.chunkId,
        user_id: vector.userId,
        embedding: vector.embedding // pgvectorè‡ªåŠ¨å¤„ç†æ•°ç»„
      });

    if (error) throw new Error(`Insert vector failed: ${error.message}`);
  }

  // å‘é‡ç›¸ä¼¼åº¦æœç´¢
  async searchSimilarVectors(
    embedding: number[],
    userId: string,
    limit: number = 10,
    threshold: number = 0.7
  ): Promise<SimilarChunk[]> {
    // è°ƒç”¨PostgreSQLå‡½æ•°
    const { data, error } = await this.client
      .rpc('search_similar_chunks', {
        query_embedding: embedding,
        query_user_id: userId,
        match_threshold: threshold,
        match_count: limit
      });

    if (error) throw new Error(`Vector search failed: ${error.message}`);

    return data.map((row: any) => ({
      chunkId: row.chunk_id,
      docId: row.doc_id,
      text: this.decrypt(
        row.encrypted_text,
        row.text_iv,
        row.text_auth_tag,
        userId
      ),
      similarity: row.similarity
    }));
  }

  // è·å–ç”¨æˆ·æ¨¡å‹
  async getUserModel(userId: string): Promise<UserModel | null> {
    const { data, error } = await this.client
      .from('user_models')
      .select('*')
      .eq('user_id', userId)
      .single();

    if (error || !data) return null;

    return {
      userId: data.user_id,
      modelId: data.model_id,
      version: data.version,
      metadata: JSON.parse(
        this.decrypt(
          data.encrypted_metadata,
          data.metadata_iv,
          data.metadata_auth_tag,
          userId
        )
      ),
      status: data.status
    };
  }

  // æ’å…¥ç”¨æˆ·æ¨¡å‹
  async insertUserModel(model: UserModel): Promise<void> {
    const { encrypted, iv, authTag } = this.encrypt(
      JSON.stringify(model.metadata),
      model.userId
    );

    const { error } = await this.client
      .from('user_models')
      .insert({
        user_id: model.userId,
        model_id: model.modelId,
        version: model.version,
        encrypted_metadata: encrypted,
        metadata_iv: iv,
        metadata_auth_tag: authTag,
        status: model.status
      });

    if (error) throw new Error(`Insert user model failed: ${error.message}`);
  }

  // æ›´æ–°ç”¨æˆ·æ¨¡å‹
  async updateUserModel(userId: string, updates: Partial<UserModel>): Promise<void> {
    const updateData: any = {};

    if (updates.status) {
      updateData.status = updates.status;
    }

    if (updates.metadata) {
      const { encrypted, iv, authTag } = this.encrypt(
        JSON.stringify(updates.metadata),
        userId
      );
      updateData.encrypted_metadata = encrypted;
      updateData.metadata_iv = iv;
      updateData.metadata_auth_tag = authTag;
    }

    const { error } = await this.client
      .from('user_models')
      .update(updateData)
      .eq('user_id', userId);

    if (error) throw new Error(`Update user model failed: ${error.message}`);
  }

  // æ’å…¥åˆè§„æ—¥å¿—
  async insertComplianceLog(log: ComplianceLog): Promise<void> {
    const { error } = await this.client
      .from('compliance_logs')
      .insert({
        user_id: log.userId,
        log_type: log.logType,
        action: log.action,
        metadata: log.metadata || {},
        ip_address: log.ipAddress,
        user_agent: log.userAgent
      });

    if (error) throw new Error(`Insert compliance log failed: ${error.message}`);
  }
}

// ============================================
// SQLiteå®ç° (å‘åå…¼å®¹)
// ============================================

export class SQLiteDatabase implements IDatabase {
  private db: Database.Database;

  constructor(config: DBConfig) {
    const filename = config.filename || './self_agent.db';
    this.db = new Database(filename);
    this.db.pragma('journal_mode = WAL');
    // ä½¿ç”¨ç°æœ‰çš„schema (from db/index.ts)
  }

  // ... å®ç°æ‰€æœ‰IDatabaseæ¥å£æ–¹æ³• (ä½¿ç”¨ç°æœ‰çš„SQLiteä»£ç )
  // è¿™é‡Œçœç•¥å…·ä½“å®ç°ï¼Œå› ä¸ºå·²ç»åœ¨db/index.tsä¸­å®Œæˆ
}

// ============================================
// æ•°æ®åº“å·¥å‚
// ============================================

let dbInstance: IDatabase | null = null;

export function getDatabaseAdapter(config?: DBConfig): IDatabase {
  if (dbInstance) return dbInstance;

  const dbType = process.env.DB_TYPE as DBType || DBType.SQLITE;
  const finalConfig: DBConfig = config || {
    type: dbType,
    filename: process.env.SELF_AGENT_DB || './self_agent.db',
    supabaseUrl: process.env.SUPABASE_URL,
    supabaseKey: process.env.SUPABASE_SERVICE_KEY,
    encryptionEnabled: process.env.E2EE_ENABLED === 'true'
  };

  if (finalConfig.type === DBType.SUPABASE) {
    console.log('ğŸš€ Using Supabase database (E2EE enabled)');
    dbInstance = new SupabaseDatabase(finalConfig);
  } else {
    console.log('ğŸ—„ï¸  Using SQLite database (local)');
    dbInstance = new SQLiteDatabase(finalConfig);
  }

  return dbInstance;
}
```

#### Step 3.3: ç¯å¢ƒå˜é‡é…ç½®
```bash
# File: Self_AI_Agent/.env.production

# ============================================
# Database Configuration
# ============================================

# æ•°æ®åº“ç±»å‹: 'sqlite' or 'supabase'
DB_TYPE=supabase

# SQLiteé…ç½® (å¼€å‘ç¯å¢ƒ)
SELF_AGENT_DB=./self_agent.db

# Supabaseé…ç½® (ç”Ÿäº§ç¯å¢ƒ)
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# ç«¯åˆ°ç«¯åŠ å¯†
E2EE_ENABLED=true

# ============================================
# Security
# ============================================

# JWTå¯†é’¥ (ç”¨äºAPIè®¤è¯)
JWT_SECRET=your-super-secret-jwt-key-change-in-production

# Encryption Key Derivation
# PBKDF2è¿­ä»£æ¬¡æ•°
PBKDF2_ITERATIONS=100000
```

#### Step 3.4: æ›´æ–°ç°æœ‰ä»£ç 
```typescript
// File: Self_AI_Agent/src/services/userModelTraining.ts
// å°†æ‰€æœ‰æ•°æ®åº“è°ƒç”¨æ”¹ä¸ºä½¿ç”¨adapter

import { getDatabaseAdapter } from '../db/adapter';

export async function trainUserSpecificModel(
  userId: string,
  forceRetrain: boolean = false
): Promise<TrainModelResult> {
  const db = getDatabaseAdapter();

  // æ£€æŸ¥ç°æœ‰æ¨¡å‹
  const existingModel = await db.getUserModel(userId);
  
  if (existingModel && !forceRetrain) {
    return {
      success: true,
      message: 'User model already exists',
      modelId: existingModel.modelId,
      metadata: existingModel.metadata
    };
  }

  // è·å–ç”¨æˆ·æ•°æ®
  const documents = await db.listDocuments(userId);
  
  if (documents.length === 0) {
    throw new Error('No training data available');
  }

  // è®­ç»ƒæ¨¡å‹...
  const modelId = `user-${userId}-${Date.now()}`;
  const metadata = {
    totalDocuments: documents.length,
    dataSources: [...new Set(documents.map(d => d.source))],
    trainingDate: new Date().toISOString()
  };

  await db.insertUserModel({
    userId,
    modelId,
    version: `v${Date.now()}`,
    metadata,
    status: 'ready'
  });

  return { success: true, modelId, metadata };
}
```

### Phase 4: æµ‹è¯•ä¸éªŒè¯ (1å°æ—¶)

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
# File: Self_AI_Agent/test/supabase-integration.test.ts

import { getDatabaseAdapter, DBType } from '../src/db/adapter';
import * as crypto from 'crypto';

describe('Supabase Integration', () => {
  let db: IDatabase;
  const testUserId = 'test@example.com';
  const masterKey = crypto.randomBytes(32); // æ¨¡æ‹Ÿç”¨æˆ·å¯†é’¥

  beforeAll(() => {
    db = getDatabaseAdapter({
      type: DBType.SUPABASE,
      supabaseUrl: process.env.SUPABASE_URL!,
      supabaseKey: process.env.SUPABASE_SERVICE_KEY!,
      encryptionEnabled: true
    });

    // è®¾ç½®åŠ å¯†å¯†é’¥
    (db as SupabaseDatabase).setUserEncryptionKey(testUserId, masterKey);
  });

  test('Insert and retrieve encrypted document', async () => {
    const doc = {
      id: `doc-${Date.now()}`,
      userId: testUserId,
      title: 'Test Document',
      content: 'This is sensitive data that should be encrypted!',
      source: 'test'
    };

    // æ’å…¥
    await db.insertDocument(doc);

    // è¯»å–
    const retrieved = await db.getDocument(doc.id, testUserId);
    expect(retrieved).not.toBeNull();
    expect(retrieved!.content).toBe(doc.content); // è‡ªåŠ¨è§£å¯†
  });

  test('Vector similarity search', async () => {
    // æ’å…¥æµ‹è¯•å‘é‡
    const chunkId = `chunk-${Date.now()}`;
    const embedding = Array.from({ length: 768 }, () => Math.random());

    await db.insertVector({
      chunkId,
      userId: testUserId,
      embedding
    });

    // æœç´¢ç›¸ä¼¼å‘é‡
    const results = await db.searchSimilarVectors(
      embedding,
      testUserId,
      10,
      0.5
    );

    expect(results.length).toBeGreaterThan(0);
    expect(results[0].similarity).toBeGreaterThan(0.99); // åº”è¯¥æ‰¾åˆ°è‡ªå·±
  });

  test('RLS prevents cross-user data access', async () => {
    const otherUserId = 'other@example.com';

    // å°è¯•è®¿é—®å…¶ä»–ç”¨æˆ·çš„æ–‡æ¡£ (åº”è¯¥è¿”å›null)
    const doc = await db.getDocument('some-doc-id', otherUserId);
    expect(doc).toBeNull();
  });
});
```

---

## ğŸ’° æˆæœ¬åˆ†æ

### MVPé˜¶æ®µ (Supabaseå…è´¹å±‚)
```
ç”¨æˆ·è§„æ¨¡: 10-50ä¸ªæ´»è·ƒç”¨æˆ·
æ•°æ®é‡: 500MBæ•°æ®åº“ + 1GBæ–‡ä»¶å­˜å‚¨
æˆæœ¬: $0/æœˆ

é™åˆ¶:
- éœ€å®šæœŸæ‰‹åŠ¨å¤‡ä»½
- 7å¤©æ— æ´»åŠ¨ä¼šæš‚åœ (è®¿é—®æ—¶è‡ªåŠ¨æ¢å¤)
```

### å°è§„æ¨¡å•†ä¸šåŒ– (Supabase Pro)
```
ç”¨æˆ·è§„æ¨¡: 100-1,000ä¸ªæ´»è·ƒç”¨æˆ·
æ•°æ®é‡: 8GBæ•°æ®åº“ + 100GBæ–‡ä»¶å­˜å‚¨
æˆæœ¬: $25/æœˆ

æ–°å¢åŠŸèƒ½:
- è‡ªåŠ¨æ¯æ—¥å¤‡ä»½ (ä¿ç•™7å¤©)
- æ— æš‚åœç­–ç•¥
- ä¼˜å…ˆæŠ€æœ¯æ”¯æŒ
- è‡ªå®šä¹‰åŸŸå
```

### ä¸­è§„æ¨¡æ‰©å±• (Supabase Team)
```
ç”¨æˆ·è§„æ¨¡: 1,000-10,000ä¸ªæ´»è·ƒç”¨æˆ·
æ•°æ®é‡: æ— é™æ•°æ®åº“ + æ— é™å­˜å‚¨
æˆæœ¬: $599/æœˆ

æ–°å¢åŠŸèƒ½:
- è‡ªåŠ¨æ¯æ—¥å¤‡ä»½ (ä¿ç•™30å¤©)
- Point-in-time recovery (æ¢å¤åˆ°ä»»æ„æ—¶é—´ç‚¹)
- ä¸“å±æ”¯æŒé€šé“
- 99.9% SLA
```

---

## ğŸš€ å•†ä¸šåŒ–æ–¹æ¡ˆ

### é˜¶æ®µ1: 1ä¸‡ç”¨æˆ·ä»¥ä¸‹ (Supabase)
```
æ¶æ„: Supabase Pro/Team
ä¼˜åŠ¿:
- å®Œå…¨æ‰˜ç®¡ (æ— è¿ç»´æˆæœ¬)
- è‡ªåŠ¨æ‰©å±•
- å…¨çƒCDN
- å†…ç½®Auth + Storage
æˆæœ¬: $25-$599/æœˆ
```

### é˜¶æ®µ2: 1ä¸‡-10ä¸‡ç”¨æˆ· (Supabase Enterprise + Redis)
```
æ¶æ„:
- ä¸»æ•°æ®åº“: Supabase Enterprise (ä¸“å±å®ä¾‹)
- ç¼“å­˜å±‚: Redis Cloud (Upstash/Redis Labs)
- å‘é‡æ•°æ®åº“: Pinecone/Qdrant (ä¸“ç”¨å‘é‡æœç´¢)

æˆæœ¬ä¼°ç®—:
- Supabase Enterprise: $2,000-$5,000/æœˆ
- Redis Cloud (10GB): $50-$200/æœˆ
- Pinecone (1Må‘é‡): $70-$280/æœˆ
æ€»è®¡: $2,120-$5,480/æœˆ
```

### é˜¶æ®µ3: 10ä¸‡ç”¨æˆ·ä»¥ä¸Š (æ··åˆäº‘æ¶æ„)
```
æ¶æ„:
- ä¸»æ•°æ®åº“: AWS RDS PostgreSQL (Multi-AZ)
  * db.r6g.2xlarge (8vCPU, 64GB RAM)
  * æˆæœ¬: ~$1,200/æœˆ
  
- å‘é‡æ•°æ®åº“: Pinecone/Milvus/Weaviate
  * Pinecone Standard (10Må‘é‡): ~$700/æœˆ
  * æˆ–è‡ªå»ºMilvusé›†ç¾¤: ~$2,000/æœˆ
  
- å¯¹è±¡å­˜å‚¨: AWS S3 + CloudFront
  * 10TBå­˜å‚¨: ~$230/æœˆ
  * 100TBä¼ è¾“: ~$8,500/æœˆ
  
- ç¼“å­˜: AWS ElastiCache Redis
  * cache.r6g.xlarge: ~$350/æœˆ
  
- è®¡ç®—: ECS Fargate / EKS
  * 20ä¸ªå®¹å™¨å®ä¾‹: ~$1,500/æœˆ
  
æ€»è®¡: ~$12,480/æœˆ (å¯æ”¯æ’‘100ä¸‡ç”¨æˆ·)

ä¼˜åŒ–é€‰é¡¹:
- ä½¿ç”¨AWS Reserved Instances: èŠ‚çœ30-50%
- CDNä½¿ç”¨Cloudflare: èŠ‚çœ70%å¸¦å®½æˆæœ¬
- å‘é‡æ•°æ®åº“è‡ªå»º: èŠ‚çœ60%
```

---

## ğŸ”’ å®‰å…¨å¢å¼ºå»ºè®®

### 1. å®¢æˆ·ç«¯åŠ å¯†å¯†é’¥ç®¡ç†
```typescript
// File: src/services/encryption.ts

import * as crypto from 'crypto';

export class EncryptionKeyManager {
  // ä»ç”¨æˆ·å¯†ç æ´¾ç”ŸåŠ å¯†å¯†é’¥
  static deriveEncryptionKey(
    password: string,
    userSalt: string
  ): { encryptionKey: Buffer; authKey: Buffer } {
    // ä½¿ç”¨PBKDF2æ´¾ç”Ÿ256ä½å¯†é’¥
    const masterKey = crypto.pbkdf2Sync(
      password,
      userSalt,
      100000, // è¿­ä»£æ¬¡æ•°
      64, // è¾“å‡º64å­—èŠ‚ (512ä½)
      'sha512'
    );

    // æ‹†åˆ†ä¸ºä¸¤ä¸ª32å­—èŠ‚å¯†é’¥
    const encryptionKey = masterKey.subarray(0, 32); // AES-256
    const authKey = masterKey.subarray(32, 64); // HMAC

    return { encryptionKey, authKey };
  }

  // ç”Ÿæˆéšæœºç›å€¼ (ç”¨æˆ·æ³¨å†Œæ—¶)
  static generateSalt(): string {
    return crypto.randomBytes(32).toString('hex');
  }
}

// ä½¿ç”¨ç¤ºä¾‹:
// 1. ç”¨æˆ·æ³¨å†Œæ—¶
const salt = EncryptionKeyManager.generateSalt();
// å­˜å‚¨åˆ°auth_users.encryption_salt

// 2. ç”¨æˆ·ç™»å½•æ—¶
const { encryptionKey } = EncryptionKeyManager.deriveEncryptionKey(
  userPassword,
  storedSalt
);

// 3. è®¾ç½®åˆ°æ•°æ®åº“é€‚é…å™¨
db.setUserEncryptionKey(userId, encryptionKey);
```

### 2. å¤‡ä»½åŠ å¯†
```bash
# å®šæœŸå¤‡ä»½åˆ°åŠ å¯†å­˜å‚¨
# File: scripts/backup-to-s3.sh

#!/bin/bash

# 1. ä»Supabaseå¯¼å‡ºæ•°æ®
pg_dump "postgresql://postgres:$DB_PASSWORD@$DB_HOST:5432/postgres" \
  --file=backup-$(date +%Y%m%d).sql

# 2. åŠ å¯†å¤‡ä»½
openssl enc -aes-256-cbc \
  -salt \
  -in backup-$(date +%Y%m%d).sql \
  -out backup-$(date +%Y%m%d).sql.enc \
  -pass file:./backup-encryption-key.txt

# 3. ä¸Šä¼ åˆ°S3 (åŠ å¯†ä¼ è¾“)
aws s3 cp backup-$(date +%Y%m%d).sql.enc \
  s3://soma-backups/$(date +%Y%m%d)/ \
  --sse AES256

# 4. åˆ é™¤æœ¬åœ°æ–‡ä»¶
rm backup-$(date +%Y%m%d).sql*
```

### 3. å®¡è®¡æ—¥å¿—
```sql
-- åˆ›å»ºå®¡è®¡è§¦å‘å™¨
CREATE OR REPLACE FUNCTION audit_table_changes()
RETURNS TRIGGER AS $$
BEGIN
  IF (TG_OP = 'DELETE') THEN
    INSERT INTO audit_logs (table_name, operation, user_id, old_data)
    VALUES (TG_TABLE_NAME, 'DELETE', OLD.user_id, row_to_json(OLD));
  ELSIF (TG_OP = 'UPDATE') THEN
    INSERT INTO audit_logs (table_name, operation, user_id, old_data, new_data)
    VALUES (TG_TABLE_NAME, 'UPDATE', NEW.user_id, row_to_json(OLD), row_to_json(NEW));
  ELSIF (TG_OP = 'INSERT') THEN
    INSERT INTO audit_logs (table_name, operation, user_id, new_data)
    VALUES (TG_TABLE_NAME, 'INSERT', NEW.user_id, row_to_json(NEW));
  END IF;
  RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- åº”ç”¨åˆ°æ•æ„Ÿè¡¨
CREATE TRIGGER audit_documents
AFTER INSERT OR UPDATE OR DELETE ON documents
FOR EACH ROW EXECUTE FUNCTION audit_table_changes();
```

---

## ğŸ“Š è¿ç§»è·¯å¾„

```
å½“å‰ (SQLiteæœ¬åœ°)
         â†“
    [æ•°æ®å¯¼å‡º]
         â†“
MVP (Supabaseå…è´¹å±‚)
  - 10-50ç”¨æˆ·
  - $0/æœˆ
  - æ‰‹åŠ¨å¤‡ä»½
         â†“
    [å‡çº§è®¢é˜…]
         â†“
å°è§„æ¨¡ (Supabase Pro)
  - 100-1,000ç”¨æˆ·
  - $25/æœˆ
  - è‡ªåŠ¨å¤‡ä»½
         â†“
    [æ·»åŠ ç¼“å­˜å±‚]
         â†“
ä¸­è§„æ¨¡ (Supabase + Redis + Pinecone)
  - 1,000-10,000ç”¨æˆ·
  - $2,000-$5,000/æœˆ
  - ä¸“ç”¨å‘é‡æœç´¢
         â†“
    [è¿ç§»åˆ°AWS]
         â†“
å¤§è§„æ¨¡ (AWS RDS + S3 + ElastiCache)
  - 10ä¸‡+ç”¨æˆ·
  - $10,000-$50,000/æœˆ
  - å®Œå…¨è‡ªä¸»æ§åˆ¶
```

---

## ğŸ¯ ç«‹å³è¡ŒåŠ¨è®¡åˆ’

### ä»Šå¤© (2å°æ—¶)
1. âœ… æ³¨å†ŒSupabaseè´¦å· (5åˆ†é’Ÿ)
2. âœ… åˆ›å»ºé¡¹ç›®å¹¶å¯ç”¨pgvector (10åˆ†é’Ÿ)
3. âœ… æ‰§è¡Œschemaè¿ç§» (20åˆ†é’Ÿ)
4. âœ… å®‰è£…ä¾èµ–åŒ… (10åˆ†é’Ÿ)
5. âœ… åˆ›å»ºæ•°æ®åº“é€‚é…å±‚ (1å°æ—¶)
6. âœ… æ›´æ–°.envé…ç½® (5åˆ†é’Ÿ)

### æœ¬å‘¨ (8å°æ—¶)
7. â³ æ›´æ–°æ‰€æœ‰æ•°æ®åº“è°ƒç”¨ (4å°æ—¶)
8. â³ å®ç°E2EEåŠ å¯†é€»è¾‘ (2å°æ—¶)
9. â³ æµ‹è¯•å‘é‡æœç´¢æ€§èƒ½ (1å°æ—¶)
10. â³ æ•°æ®è¿ç§»è„šæœ¬ (1å°æ—¶)

### ä¸‹å‘¨ (æµ‹è¯•ä¸ä¼˜åŒ–)
11. â³ ç«¯åˆ°ç«¯æµ‹è¯• (2å°æ—¶)
12. â³ æ€§èƒ½åŸºå‡†æµ‹è¯• (2å°æ—¶)
13. â³ å®‰å…¨å®¡è®¡ (2å°æ—¶)
14. â³ æ–‡æ¡£æ›´æ–° (1å°æ—¶)

---

## ğŸ“ æ”¯æŒèµ„æº

### Supabaseå®˜æ–¹æ–‡æ¡£
- Quickstart: https://supabase.com/docs/guides/getting-started
- pgvector Guide: https://supabase.com/docs/guides/ai/vector-columns
- Row Level Security: https://supabase.com/docs/guides/auth/row-level-security
- Backup & Restore: https://supabase.com/docs/guides/platform/backups

### ç¤¾åŒºèµ„æº
- Supabase Discord: https://discord.supabase.com
- GitHub Issues: https://github.com/supabase/supabase/issues

---

## ğŸ“ æ€»ç»“

### MVPæ¨èæ–¹æ¡ˆ: Supabase å…è´¹å±‚
- âœ… **æˆæœ¬**: $0/æœˆ
- âœ… **æ—¶é—´**: 2å°æ—¶å®æ–½
- âœ… **å®‰å…¨**: E2EE + RLS + SOC2
- âœ… **æ€§èƒ½**: pgvectoråŸç”Ÿæ”¯æŒ
- âœ… **æ‰©å±•**: å¹³æ»‘å‡çº§åˆ°Pro/Enterprise

### å•†ä¸šåŒ–è·¯å¾„æ¸…æ™°
```
$0/æœˆ (MVP) â†’ $25/æœˆ (100ç”¨æˆ·) â†’ $599/æœˆ (1ä¸‡ç”¨æˆ·) â†’ $10,000/æœˆ (10ä¸‡ç”¨æˆ·)
```

### ç«‹å³å¼€å§‹
```bash
# 1. æ³¨å†ŒSupabase
open https://supabase.com

# 2. åˆ›å»ºé¡¹ç›®å¹¶è·å–credentials

# 3. æ‰§è¡Œæœ¬æ–‡æ¡£ä¸­çš„ä»£ç 

# 4. å¼€å§‹æµ‹è¯•ï¼
```

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ20æ—¥  
**çŠ¶æ€**: âœ… å°±ç»ªå®æ–½
