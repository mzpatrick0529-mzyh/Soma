"""
é«˜çº§è®­ç»ƒæ ·æœ¬å¢å¼ºå™¨
æ”¯æŒé£æ ¼è¿ç§»ã€åœºæ™¯æ³›åŒ–ã€å…³ç³»å¯¹æ¯”ã€å›°éš¾è´Ÿæ ·æœ¬æŒ–æ˜
"""

import os
import json
import sqlite3
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import numpy as np
from datetime import datetime
import hashlib

@dataclass
class EnhancedSample:
    """å¢å¼ºåçš„è®­ç»ƒæ ·æœ¬"""
    id: str
    user_id: str
    original_sample_id: Optional[str]  # åŸå§‹æ ·æœ¬ID (å¦‚æœæ˜¯å¢å¼ºç”Ÿæˆçš„)
    
    # æ ¸å¿ƒå†…å®¹
    conversation_context: str
    user_response: str
    target_person: Optional[str]
    
    # å¢å¼ºæ ‡è®°
    augmentation_type: str  # 'original', 'style_transfer', 'scenario', 'relationship', 'hard_negative'
    augmentation_metadata: Dict[str, Any]
    
    # è´¨é‡ä¸æ ‡ç­¾
    quality_score: float
    style_tags: str
    intent_tags: str
    emotional_context: Optional[str]
    
    # å…ƒä¿¡æ¯
    created_at: int


class TrainingSampleAugmenter:
    """è®­ç»ƒæ ·æœ¬å¢å¼ºå™¨"""
    
    def __init__(self, db_path: str = './self_agent.db'):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        
    def augment_all(
        self,
        user_id: str,
        enable_style_transfer: bool = True,
        enable_scenario_variants: bool = True,
        enable_relationship_variants: bool = True,
        enable_hard_negatives: bool = True,
        target_multiplier: float = 3.0  # ç›®æ ‡æ˜¯åŸå§‹æ ·æœ¬æ•°çš„3å€
    ) -> List[EnhancedSample]:
        """
        å…¨é¢å¢å¼ºè®­ç»ƒæ ·æœ¬
        
        Args:
            user_id: ç”¨æˆ·ID
            enable_*: å„ç§å¢å¼ºç­–ç•¥å¼€å…³
            target_multiplier: ç›®æ ‡æ ·æœ¬å€æ•°
            
        Returns:
            å¢å¼ºåçš„æ ·æœ¬åˆ—è¡¨
        """
        print(f"\nğŸ”„ [Augmentation] Starting comprehensive sample augmentation for user: {user_id}")
        
        # 1. è·å–åŸå§‹æ ·æœ¬
        original_samples = self._load_original_samples(user_id)
        print(f"   ğŸ“Š Loaded {len(original_samples)} original samples")
        
        enhanced_samples = []
        
        # 2. ä¿ç•™æ‰€æœ‰åŸå§‹æ ·æœ¬
        for sample in original_samples:
            enhanced = self._sample_to_enhanced(sample, 'original')
            enhanced_samples.append(enhanced)
        
        # è®¡ç®—éœ€è¦ç”Ÿæˆçš„å¢å¼ºæ ·æœ¬æ•°
        current_count = len(original_samples)
        target_count = int(current_count * target_multiplier)
        needed_augmented = target_count - current_count
        
        print(f"   ğŸ¯ Target: {target_count} samples (need {needed_augmented} augmented)")
        
        # 3. é£æ ¼è¿ç§»å¢å¼º
        if enable_style_transfer and needed_augmented > 0:
            style_samples = self._generate_style_variants(
                user_id,
                original_samples,
                count=min(needed_augmented // 3, len(original_samples))
            )
            enhanced_samples.extend(style_samples)
            print(f"   âœ“ Generated {len(style_samples)} style-transferred samples")
        
        # 4. åœºæ™¯æ³›åŒ–å¢å¼º
        if enable_scenario_variants and needed_augmented > 0:
            scenario_samples = self._generate_scenario_variants(
                user_id,
                original_samples,
                count=min(needed_augmented // 3, len(original_samples))
            )
            enhanced_samples.extend(scenario_samples)
            print(f"   âœ“ Generated {len(scenario_samples)} scenario-variant samples")
        
        # 5. å…³ç³»å¯¹æ¯”å¢å¼º
        if enable_relationship_variants and needed_augmented > 0:
            relationship_samples = self._generate_relationship_variants(
                user_id,
                original_samples,
                count=min(needed_augmented // 4, len(original_samples))
            )
            enhanced_samples.extend(relationship_samples)
            print(f"   âœ“ Generated {len(relationship_samples)} relationship-variant samples")
        
        # 6. å›°éš¾è´Ÿæ ·æœ¬æŒ–æ˜
        if enable_hard_negatives:
            negative_samples = self._mine_hard_negatives(
                user_id,
                original_samples,
                count=min(50, len(original_samples) // 2)
            )
            enhanced_samples.extend(negative_samples)
            print(f"   âœ“ Mined {len(negative_samples)} hard negative samples")
        
        # 7. æŒä¹…åŒ–å¢å¼ºæ ·æœ¬
        self._save_enhanced_samples(enhanced_samples)
        
        print(f"   âœ… Total enhanced samples: {len(enhanced_samples)}")
        print(f"   ğŸ“ˆ Augmentation ratio: {len(enhanced_samples) / len(original_samples):.2f}x")
        
        return enhanced_samples
    
    def _load_original_samples(self, user_id: str) -> List[Dict[str, Any]]:
        """åŠ è½½åŸå§‹è®­ç»ƒæ ·æœ¬"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT 
                id, user_id, conversation_context, user_response,
                target_person, emotional_context, quality_score,
                style_tags, intent_tags, created_at
            FROM personality_training_samples
            WHERE user_id = ? AND used_for_training = 0
            ORDER BY quality_score DESC
        """, (user_id,))
        
        samples = []
        for row in cursor.fetchall():
            samples.append(dict(row))
        
        return samples
    
    def _sample_to_enhanced(
        self,
        sample: Dict[str, Any],
        aug_type: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> EnhancedSample:
        """å°†æ ·æœ¬è½¬æ¢ä¸ºEnhancedSample"""
        return EnhancedSample(
            id=sample.get('id', self._generate_id()),
            user_id=sample['user_id'],
            original_sample_id=sample.get('id') if aug_type != 'original' else None,
            conversation_context=sample['conversation_context'],
            user_response=sample['user_response'],
            target_person=sample.get('target_person'),
            augmentation_type=aug_type,
            augmentation_metadata=metadata or {},
            quality_score=sample.get('quality_score', 0.5),
            style_tags=sample.get('style_tags', ''),
            intent_tags=sample.get('intent_tags', ''),
            emotional_context=sample.get('emotional_context'),
            created_at=sample.get('created_at', int(datetime.now().timestamp() * 1000))
        )
    
    def _generate_style_variants(
        self,
        user_id: str,
        samples: List[Dict[str, Any]],
        count: int
    ) -> List[EnhancedSample]:
        """
        é£æ ¼è¿ç§»å¢å¼º: ä¿æŒè¯­ä¹‰,æ”¹å˜è¡¨è¾¾é£æ ¼
        
        ç­–ç•¥:
        1. æ­£å¼â†’éæ­£å¼ / éæ­£å¼â†’æ­£å¼
        2. ç®€æ´â†’è¯¦ç»† / è¯¦ç»†â†’ç®€æ´
        3. ç›´æ¥â†’å§”å©‰ / å§”å©‰â†’ç›´æ¥
        """
        enhanced = []
        
        # éœ€è¦è°ƒç”¨LLMè¿›è¡Œé£æ ¼è¿ç§»,è¿™é‡Œç®€åŒ–ä¸ºè§„åˆ™å˜æ¢ç¤ºä¾‹
        # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Gemini API
        
        import random
        selected = random.sample(samples, min(count, len(samples)))
        
        for sample in selected:
            response = sample['user_response']
            
            # ç®€å•çš„é£æ ¼å˜æ¢è§„åˆ™ (ç¤ºä¾‹)
            variants = []
            
            # å˜ä½“1: æ·»åŠ ç¤¼è²Œç”¨è¯­
            if 'å—' in response or 'å‘¢' in response:
                formal = response.replace('å—', 'å‘¢').replace('å‘¢', 'å—')
                variants.append(('formality_shift', formal))
            
            # å˜ä½“2: æ”¹å˜è¯­æ°”
            if '!' in response:
                calm = response.replace('!', 'ã€‚')
                variants.append(('tone_shift', calm))
            elif 'ã€‚' in response:
                excited = response.replace('ã€‚', '!')
                variants.append(('tone_shift', excited))
            
            # å˜ä½“3: è¯¦ç»†ç¨‹åº¦è°ƒæ•´
            if len(response) < 20:
                # æ‰©å±•ç®€çŸ­å›å¤ (å®é™…åº”ç”¨LLM)
                detailed = response + "ï¼Œè¿™æ˜¯æˆ‘çš„æƒ³æ³•ã€‚"
                variants.append(('elaboration', detailed))
            
            for variant_type, variant_text in variants[:1]:  # æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ1ä¸ªå˜ä½“
                metadata = {
                    'transform_type': variant_type,
                    'original_response': response,
                    'transform_method': 'rule_based'  # æˆ– 'llm_based'
                }
                
                aug_sample = dict(sample)
                aug_sample['id'] = self._generate_id()
                aug_sample['user_response'] = variant_text
                aug_sample['quality_score'] = sample['quality_score'] * 0.9  # ç•¥å¾®é™ä½è´¨é‡åˆ†
                
                enhanced.append(
                    self._sample_to_enhanced(aug_sample, 'style_transfer', metadata)
                )
        
        return enhanced
    
    def _generate_scenario_variants(
        self,
        user_id: str,
        samples: List[Dict[str, Any]],
        count: int
    ) -> List[EnhancedSample]:
        """
        åœºæ™¯æ³›åŒ–å¢å¼º: ç›¸åŒè¯­ä¹‰,ä¸åŒæƒ…å¢ƒ
        
        ç­–ç•¥:
        1. æ”¹å˜æ—¶é—´èƒŒæ™¯ (å·¥ä½œæ—¶é—´ vs ä¼‘æ¯æ—¶é—´)
        2. æ”¹å˜åœ°ç‚¹èƒŒæ™¯ (åŠå…¬å®¤ vs å®¶é‡Œ)
        3. æ”¹å˜æƒ…ç»ªçŠ¶æ€ (å¹³é™ vs å…´å¥‹)
        """
        enhanced = []
        
        import random
        selected = random.sample(samples, min(count, len(samples)))
        
        scenario_templates = [
            {
                'name': 'work_context',
                'context_prefix': 'åœ¨å·¥ä½œåœºåˆ,',
                'formality_boost': 0.2
            },
            {
                'name': 'casual_context',
                'context_prefix': 'åœ¨è½»æ¾çš„èŠå¤©ä¸­,',
                'formality_boost': -0.2
            },
            {
                'name': 'emotional_support',
                'context_prefix': 'åœ¨æä¾›æƒ…æ„Ÿæ”¯æŒæ—¶,',
                'formality_boost': 0.0
            }
        ]
        
        for sample in selected:
            scenario = random.choice(scenario_templates)
            
            # ä¿®æ”¹context
            new_context = scenario['context_prefix'] + sample['conversation_context']
            
            metadata = {
                'scenario_type': scenario['name'],
                'original_context': sample['conversation_context'],
                'context_modification': scenario['context_prefix']
            }
            
            aug_sample = dict(sample)
            aug_sample['id'] = self._generate_id()
            aug_sample['conversation_context'] = new_context
            aug_sample['quality_score'] = sample['quality_score'] * 0.85
            
            # æ›´æ–°æƒ…æ„Ÿæ ‡ç­¾
            if scenario['name'] == 'emotional_support':
                aug_sample['emotional_context'] = 'supportive'
            
            enhanced.append(
                self._sample_to_enhanced(aug_sample, 'scenario', metadata)
            )
        
        return enhanced
    
    def _generate_relationship_variants(
        self,
        user_id: str,
        samples: List[Dict[str, Any]],
        count: int
    ) -> List[EnhancedSample]:
        """
        å…³ç³»å¯¹æ¯”å¢å¼º: ç›¸åŒå†…å®¹å¯¹ä¸åŒäººçš„è¡¨è¾¾
        
        ç­–ç•¥:
        1. å¯¹é™Œç”Ÿäºº â†’ æ›´æ­£å¼ã€ä¿å®ˆ
        2. å¯¹äº²å¯†æœ‹å‹ â†’ æ›´éšæ„ã€å¼€æ”¾
        3. å¯¹æƒå¨äººç‰© â†’ æ›´è°¨æ…ã€ç¤¼è²Œ
        """
        enhanced = []
        
        # è·å–ç”¨æˆ·çš„å…³ç³»å›¾è°±
        relationships = self._get_user_relationships(user_id)
        
        if not relationships:
            print("   âš ï¸  No relationship data found, skipping relationship variants")
            return enhanced
        
        import random
        selected = random.sample(samples, min(count, len(samples)))
        
        for sample in selected:
            # ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆé¢å‘ä¸åŒå…³ç³»çš„å˜ä½“
            for rel in random.sample(relationships, min(2, len(relationships))):
                person_id = rel['person_id']
                intimacy = rel.get('intimacy_level', 0.5)
                
                # æ ¹æ®äº²å¯†åº¦è°ƒæ•´å›å¤ (å®é™…åº”ç”¨LLM)
                response = sample['user_response']
                
                if intimacy < 0.3:  # é™Œç”Ÿ/ç–è¿œ
                    # å¢åŠ ç¤¼è²Œç”¨è¯­
                    adjusted_response = "æ‚¨å¥½ï¼Œ" + response if not response.startswith(('ä½ ', 'æ‚¨')) else response
                elif intimacy > 0.7:  # äº²å¯†
                    # å¢åŠ äº²æ˜µè¡¨è¾¾
                    adjusted_response = response + " ğŸ˜Š" if 'ğŸ˜Š' not in response else response
                else:
                    adjusted_response = response
                
                metadata = {
                    'target_relationship': person_id,
                    'intimacy_level': intimacy,
                    'original_person': sample.get('target_person'),
                    'adjustment_type': 'intimacy_based'
                }
                
                aug_sample = dict(sample)
                aug_sample['id'] = self._generate_id()
                aug_sample['target_person'] = person_id
                aug_sample['user_response'] = adjusted_response
                aug_sample['quality_score'] = sample['quality_score'] * 0.8
                
                enhanced.append(
                    self._sample_to_enhanced(aug_sample, 'relationship', metadata)
                )
        
        return enhanced
    
    def _mine_hard_negatives(
        self,
        user_id: str,
        samples: List[Dict[str, Any]],
        count: int
    ) -> List[EnhancedSample]:
        """
        å›°éš¾è´Ÿæ ·æœ¬æŒ–æ˜
        
        ç­–ç•¥:
        1. è¯­ä¹‰ç›¸è¿‘ä½†é£æ ¼ä¸ç¬¦çš„å›å¤
        2. äº‹å®æ­£ç¡®ä½†æƒ…æ„Ÿä¸åŒ¹é…çš„å›å¤
        3. å…¶ä»–ç”¨æˆ·çš„ç›¸ä¼¼åœºæ™¯å›å¤
        """
        enhanced = []
        
        import random
        selected = random.sample(samples, min(count, len(samples)))
        
        for sample in selected:
            # ç±»å‹1: é£æ ¼å¯¹ç«‹çš„è´Ÿæ ·æœ¬
            response = sample['user_response']
            
            # ç®€å•åå‘å˜æ¢ (å®é™…åº”ç”¨å¯¹æ¯”å­¦ä¹ æŒ–æ˜)
            if '!' in response:
                negative_response = response.replace('!', 'â€¦')  # å…´å¥‹â†’çŠ¹è±«
            elif len(response) > 30:
                negative_response = response[:15] + 'ã€‚'  # è¯¦ç»†â†’ç®€çŸ­
            else:
                negative_response = 'å—¯ï¼Œ' + response  # æœæ–­â†’çŠ¹è±«
            
            metadata = {
                'negative_type': 'style_mismatch',
                'original_response': response,
                'mismatch_dimension': 'tone'
            }
            
            aug_sample = dict(sample)
            aug_sample['id'] = self._generate_id()
            aug_sample['user_response'] = negative_response
            aug_sample['quality_score'] = 0.3  # è´Ÿæ ·æœ¬ä½åˆ†
            
            # æ ‡è®°ä¸ºè´Ÿæ ·æœ¬
            neg_sample = self._sample_to_enhanced(aug_sample, 'hard_negative', metadata)
            neg_sample.augmentation_metadata['is_negative'] = True
            
            enhanced.append(neg_sample)
        
        return enhanced
    
    def _get_user_relationships(self, user_id: str) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·å…³ç³»æ•°æ®"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT DISTINCT target_person as person_id, 
                   COUNT(*) as interaction_count
            FROM personality_training_samples
            WHERE user_id = ? AND target_person IS NOT NULL
            GROUP BY target_person
            HAVING interaction_count >= 3
        """, (user_id,))
        
        relationships = []
        for row in cursor.fetchall():
            relationships.append({
                'person_id': row[0],
                'interaction_count': row[1],
                'intimacy_level': min(row[1] / 100, 1.0)  # ç®€åŒ–ä¼°è®¡
            })
        
        return relationships
    
    def _save_enhanced_samples(self, samples: List[EnhancedSample]):
        """ä¿å­˜å¢å¼ºæ ·æœ¬åˆ°æ•°æ®åº“"""
        cursor = self.conn.cursor()
        
        # åˆ›å»ºå¢å¼ºæ ·æœ¬è¡¨(å¦‚æœä¸å­˜åœ¨)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS enhanced_training_samples (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                original_sample_id TEXT,
                conversation_context TEXT,
                user_response TEXT,
                target_person TEXT,
                augmentation_type TEXT,
                augmentation_metadata TEXT,
                quality_score REAL,
                style_tags TEXT,
                intent_tags TEXT,
                emotional_context TEXT,
                used_for_training INTEGER DEFAULT 0,
                created_at INTEGER,
                FOREIGN KEY(user_id) REFERENCES users(id)
            )
        """)
        
        # æ‰¹é‡æ’å…¥
        for sample in samples:
            cursor.execute("""
                INSERT OR REPLACE INTO enhanced_training_samples
                (id, user_id, original_sample_id, conversation_context, user_response,
                 target_person, augmentation_type, augmentation_metadata, quality_score,
                 style_tags, intent_tags, emotional_context, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                sample.id,
                sample.user_id,
                sample.original_sample_id,
                sample.conversation_context,
                sample.user_response,
                sample.target_person,
                sample.augmentation_type,
                json.dumps(sample.augmentation_metadata),
                sample.quality_score,
                sample.style_tags,
                sample.intent_tags,
                sample.emotional_context,
                sample.created_at
            ))
        
        self.conn.commit()
        print(f"   ğŸ’¾ Saved {len(samples)} enhanced samples to database")
    
    def _generate_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        return hashlib.md5(
            f"{datetime.now().timestamp()}-{np.random.random()}".encode()
        ).hexdigest()[:16]
    
    def get_augmentation_stats(self, user_id: str) -> Dict[str, Any]:
        """è·å–å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        cursor = self.conn.cursor()
        
        # æŒ‰å¢å¼ºç±»å‹ç»Ÿè®¡
        cursor.execute("""
            SELECT augmentation_type, COUNT(*) as count
            FROM enhanced_training_samples
            WHERE user_id = ?
            GROUP BY augmentation_type
        """, (user_id,))
        
        type_dist = {row[0]: row[1] for row in cursor.fetchall()}
        
        # è´¨é‡åˆ†å¸ƒ
        cursor.execute("""
            SELECT 
                CASE 
                    WHEN quality_score < 0.3 THEN 'low'
                    WHEN quality_score < 0.7 THEN 'medium'
                    ELSE 'high'
                END as quality_level,
                COUNT(*) as count
            FROM enhanced_training_samples
            WHERE user_id = ?
            GROUP BY quality_level
        """, (user_id,))
        
        quality_dist = {row[0]: row[1] for row in cursor.fetchall()}
        
        return {
            'type_distribution': type_dist,
            'quality_distribution': quality_dist,
            'total_samples': sum(type_dist.values())
        }
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'conn'):
            self.conn.close()


def main():
    """æµ‹è¯•å¢å¼ºå™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ ·æœ¬å¢å¼ºå™¨')
    parser.add_argument('--user-id', type=str, default='default', help='ç”¨æˆ·ID')
    parser.add_argument('--db-path', type=str, default='./self_agent.db', help='æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--multiplier', type=float, default=3.0, help='å¢å¼ºå€æ•°')
    
    args = parser.parse_args()
    
    augmenter = TrainingSampleAugmenter(args.db_path)
    
    # æ‰§è¡Œå¢å¼º
    enhanced_samples = augmenter.augment_all(
        user_id=args.user_id,
        target_multiplier=args.multiplier
    )
    
    # è¾“å‡ºç»Ÿè®¡
    stats = augmenter.get_augmentation_stats(args.user_id)
    print(f"\nğŸ“Š Augmentation Statistics:")
    print(f"   Type Distribution: {json.dumps(stats['type_distribution'], indent=2)}")
    print(f"   Quality Distribution: {json.dumps(stats['quality_distribution'], indent=2)}")
    print(f"   Total Samples: {stats['total_samples']}")


if __name__ == '__main__':
    main()
