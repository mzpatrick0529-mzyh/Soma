# Personality V2.0 éƒ¨ç½²æŒ‡å—

> **ç›®æ ‡**: 95%+ Turing Test Pass Rate  
> **æ¶æ„**: AI-Native Memory (HMM + Me-Alignment)  
> **ç‰ˆæœ¬**: 2.0.0

---

## å¿«é€Ÿå¼€å§‹ (5åˆ†é’Ÿ)

### 1. æ•°æ®åº“åˆå§‹åŒ–

```bash
cd /Users/patrick_ma/Soma/Soma_V0/Self_AI_Agent

# åˆ›å»ºV2.0è¡¨ç»“æ„
sqlite3 self_agent.db < src/db/ai_native_memory_schema.sql

# éªŒè¯è¡¨åˆ›å»º
sqlite3 self_agent.db "SELECT name FROM sqlite_master WHERE type='table' AND (name LIKE 'l0_%' OR name LIKE 'l1_%' OR name LIKE 'l2_%');"
```

é¢„æœŸè¾“å‡º: 13ä¸ªè¡¨å (l0_raw_memories, l1_memory_clusters, l2_biography, etc.)

### 2. å®‰è£…Pythonä¾èµ–

```bash
# å®‰è£…ML/NLPåº“
pip3 install scikit-learn umap-learn sentence-transformers spacy textblob hdbscan

# ä¸‹è½½spaCyè¯­è¨€æ¨¡å‹
python3 -m spacy download en_core_web_sm

# ä¸‹è½½NLTKæ•°æ®
python3 -m nltk.downloader vader_lexicon
```

### 3. æµ‹è¯•HMMç³»ç»Ÿ

```bash
# æµ‹è¯•L0è®°å¿†å­˜å‚¨
python3 src/ml/hierarchical_memory_manager.py \
  --db-path ./self_agent.db \
  --user-id test@example.com \
  --action store \
  --content "I love hiking in the mountains" \
  --source "test"

# è¿è¡Œèšç±»
python3 src/ml/hierarchical_memory_manager.py \
  --db-path ./self_agent.db \
  --user-id test@example.com \
  --action cluster

# ç”Ÿæˆä¼ è®°
python3 src/ml/hierarchical_memory_manager.py \
  --db-path ./self_agent.db \
  --user-id test@example.com \
  --action biography
```

### 4. æµ‹è¯•Me-Alignmentå¼•æ“

```bash
python3 src/ml/me_alignment_engine.py \
  --db-path ./self_agent.db \
  --user-id test@example.com \
  --input "What do you think about nature?"
```

é¢„æœŸè¾“å‡º: ç”Ÿæˆå›å¤ + 4ç»´ä¸€è‡´æ€§è¯„åˆ†

---

## å®Œæ•´éƒ¨ç½²æµç¨‹

### Phase 1: åŸºç¡€æ¶æ„ (Week 1)

#### æ­¥éª¤1.1: æ•°æ®åº“è¿ç§»

**ç›®æ ‡**: å°†V1.0æ•°æ®è¿ç§»åˆ°V2.0æ¶æ„

```bash
# åˆ›å»ºè¿ç§»è„šæœ¬
cat > migrate_v1_to_v2.py << 'EOF'
import sqlite3
import json
from datetime import datetime

def migrate():
    conn = sqlite3.connect('self_agent.db')
    cursor = conn.cursor()
    
    # ä»V1.0çš„chunksè¡¨è¿ç§»åˆ°L0
    cursor.execute("""
        INSERT INTO l0_raw_memories (
            id, user_id, content, timestamp, source, 
            conversation_id, importance
        )
        SELECT 
            'migrated_' || id,
            user_id,
            content,
            created_at,
            'v1_migration',
            'migration_batch_1',
            0.5
        FROM chunks
        WHERE user_id IS NOT NULL
    """)
    
    migrated = cursor.rowcount
    conn.commit()
    conn.close()
    
    print(f"âœ… Migrated {migrated} memories from V1.0 to L0")

if __name__ == "__main__":
    migrate()
EOF

python3 migrate_v1_to_v2.py
```

#### æ­¥éª¤1.2: ç”Ÿæˆåˆå§‹è®°å¿†å±‚æ¬¡

```bash
# ä¸ºæ¯ä¸ªç”¨æˆ·æ„å»ºå®Œæ•´å±‚æ¬¡
python3 src/ml/hierarchical_memory_manager.py \
  --db-path ./self_agent.db \
  --user-id mzpatrick0529@gmail.com \
  --action full
```

é¢„æœŸ: 
- L0: æ‰€æœ‰å†å²è®°å¿† (200+ memories)
- L1: 10-30ä¸ªä¸»é¢˜èšç±»
- L2: å®Œæ•´ä¼ è®° (quality_score > 0.8)

#### æ­¥éª¤1.3: é›†æˆLLM

**ä¿®æ”¹**: `hierarchical_memory_manager.py` å’Œ `me_alignment_engine.py`

```python
# æ›¿æ¢mockå‡½æ•°ä¸ºçœŸå®Geminiè°ƒç”¨
def llm_generate(prompt: str) -> str:
    import google.generativeai as genai
    
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    model = genai.GenerativeModel('gemini-pro')
    
    response = model.generate_content(prompt)
    return response.text
```

### Phase 2: APIé›†æˆ (Week 2)

#### æ­¥éª¤2.1: æ³¨å†ŒV2.0è·¯ç”±

**ä¿®æ”¹**: `src/server.ts`

```typescript
import memoryV2Routes from './routes/memoryV2.js';

// æ·»åŠ è·¯ç”±
app.use('/api/memory/v2', memoryV2Routes);
```

#### æ­¥éª¤2.2: æµ‹è¯•APIç«¯ç‚¹

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:3001/api/memory/v2/health

# L0å­˜å‚¨
curl -X POST http://localhost:3001/api/memory/v2/test@example.com/l0/store \
  -H "Content-Type: application/json" \
  -d '{"content": "Test memory", "source": "api_test"}'

# L1èšç±»
curl -X POST http://localhost:3001/api/memory/v2/test@example.com/l1/cluster

# L2ä¼ è®°
curl http://localhost:3001/api/memory/v2/test@example.com/l2/biography

# Me-Alignmentç”Ÿæˆ
curl -X POST http://localhost:3001/api/memory/v2/test@example.com/generate \
  -H "Content-Type: application/json" \
  -d '{"currentInput": "What do you like to do?"}'
```

#### æ­¥éª¤2.3: ä¿®å¤TypeScriptå¯¼å…¥é”™è¯¯

**é—®é¢˜**: `memoryV2Service.ts` line 10 - `db` not exported

**è§£å†³æ–¹æ¡ˆ**:

```typescript
// æ–¹æ¡ˆ1: ä½¿ç”¨Databaseç±»
import Database from 'better-sqlite3';
export class MemoryV2Service {
  private db: Database.Database;
  
  constructor(dbPath?: string) {
    this.dbPath = dbPath || path.join(process.cwd(), 'self_agent.db');
    this.db = new Database(this.dbPath);
  }
}

// æ–¹æ¡ˆ2: åˆ›å»ºå•ç‹¬çš„dbè¿æ¥
import { createDbConnection } from '../db/index.js';
const db = createDbConnection();
```

### Phase 3: å›¾çµæµ‹è¯•éªŒè¯ (Week 3-4)

#### æ­¥éª¤3.1: å‡†å¤‡æµ‹è¯•é›†

åˆ›å»º `turing_test_samples.json`:

```json
[
  {
    "user_id": "mzpatrick0529@gmail.com",
    "context": "æœ‹å‹é—®å‘¨æœ«è®¡åˆ’",
    "input": "å‘¨æœ«æœ‰ç©ºå—ï¼Ÿè¦ä¸è¦å‡ºå»ç©ï¼Ÿ",
    "expected_traits": ["è¯­è¨€é£æ ¼: éšæ„", "æƒ…æ„Ÿ: ç§¯æ", "å†³ç­–: åŸºäºå…´è¶£"]
  },
  {
    "user_id": "mzpatrick0529@gmail.com",
    "context": "å·¥ä½œè®¨è®º",
    "input": "è¿™ä¸ªé¡¹ç›®deadlineå¤ªç´§äº†ï¼Œæ€ä¹ˆåŠï¼Ÿ",
    "expected_traits": ["è¯­è¨€é£æ ¼: ä¸“ä¸š", "æƒ…æ„Ÿ: å†·é™", "æ€ç»´: åˆ†æå‹"]
  }
]
```

#### æ­¥éª¤3.2: è¿è¡Œæµ‹è¯•

```python
import json
from me_alignment_engine import MeAlignmentEngine, GenerationContext

# åŠ è½½æµ‹è¯•é›†
with open('turing_test_samples.json') as f:
    samples = json.load(f)

engine = MeAlignmentEngine('self_agent.db', llm_generate)

results = []
for sample in samples:
    context = GenerationContext(
        user_id=sample['user_id'],
        current_input=sample['input'],
        conversation_history=[],
        scene=sample['context']
    )
    
    result = engine.generate_response(context)
    
    # è¯„ä¼°
    passed = (
        result.alignment_score.total_score > 0.95 and
        result.alignment_score.linguistic_score > 0.95 and
        result.alignment_score.emotional_score > 0.92 and
        result.alignment_score.value_score > 0.95 and
        result.alignment_score.factual_score > 0.98
    )
    
    results.append({
        'input': sample['input'],
        'response': result.response,
        'alignment_score': result.alignment_score.total_score,
        'passed': passed
    })

pass_rate = sum(r['passed'] for r in results) / len(results)
print(f"Turing Test Pass Rate: {pass_rate * 100:.1f}%")
```

**ç›®æ ‡**: Pass Rate > 95%

### Phase 4: RLHFä¼˜åŒ– (Week 5-6)

#### æ­¥éª¤4.1: æ”¶é›†ç”¨æˆ·åé¦ˆ

**å‰ç«¯é›†æˆ**:

```typescript
// åœ¨èŠå¤©ç•Œé¢æ·»åŠ è¯„åˆ†ç»„ä»¶
async function submitFeedback(
  response: string, 
  rating: number, 
  feedbackText?: string
) {
  await fetch(`/api/memory/v2/${userId}/feedback`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      response,
      context: { currentInput, conversationHistory },
      rating,
      feedbackText
    })
  });
}
```

#### æ­¥éª¤4.2: RLHFè®­ç»ƒ

```python
# åˆ›å»º rlhf_trainer.py
from transformers import AutoModelForCausalLM, Trainer
import torch

class RLHFTrainer:
    def __init__(self, db_path):
        self.db_path = db_path
        self.model = AutoModelForCausalLM.from_pretrained("gpt2")
    
    def collect_samples(self):
        """ä»me_alignment_samplesæ”¶é›†è®­ç»ƒæ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT context_memories, conversation_history, 
                   current_input, generated_response, reward
            FROM me_alignment_samples
            WHERE reward IS NOT NULL
            ORDER BY created_at DESC
            LIMIT 1000
        """)
        
        samples = cursor.fetchall()
        conn.close()
        return samples
    
    def train(self):
        """PPOè®­ç»ƒ"""
        samples = self.collect_samples()
        # TODO: å®ç°PPOè®­ç»ƒå¾ªç¯
        pass
```

---

## å‰ç«¯UIé›†æˆ

### è®°å¿†å¯è§†åŒ–ç»„ä»¶

åˆ›å»º `src/components/MemoryVisualization.tsx`:

```typescript
import React, { useEffect, useState } from 'react';
import { memoryV2Service } from '../services/memoryV2Service';

export function MemoryTimeline({ userId }: { userId: string }) {
  const [memories, setMemories] = useState([]);
  
  useEffect(() => {
    fetch(`/api/memory/v2/${userId}/l0/retrieve?limit=50`)
      .then(res => res.json())
      .then(data => setMemories(data.memories));
  }, [userId]);
  
  return (
    <div className="memory-timeline">
      {memories.map(mem => (
        <div key={mem.id} className="memory-card">
          <div className="timestamp">{mem.timestamp}</div>
          <div className="content">{mem.content}</div>
          <div className="metadata">
            <span className="sentiment">{mem.sentiment_score > 0 ? 'ğŸ˜Š' : 'ğŸ˜'}</span>
            <span className="source">{mem.source}</span>
          </div>
        </div>
      ))}
    </div>
  );
}

export function TopicGraph({ userId }: { userId: string }) {
  const [clusters, setClusters] = useState([]);
  
  useEffect(() => {
    fetch(`/api/memory/v2/${userId}/l1/clusters`)
      .then(res => res.json())
      .then(data => setClusters(data.clusters));
  }, [userId]);
  
  return (
    <div className="topic-graph">
      {clusters.map(cluster => (
        <div key={cluster.id} className="topic-node">
          <h3>{cluster.clusterName}</h3>
          <div className="keywords">
            {cluster.keywords.map(kw => (
              <span key={kw.word} className="keyword">{kw.word}</span>
            ))}
          </div>
          <div className="stats">
            {cluster.memoryCount} memories
          </div>
        </div>
      ))}
    </div>
  );
}

export function BiographyCard({ userId }: { userId: string }) {
  const [biography, setBiography] = useState(null);
  
  useEffect(() => {
    fetch(`/api/memory/v2/${userId}/l2/biography`)
      .then(res => res.json())
      .then(data => setBiography(data.biography));
  }, [userId]);
  
  if (!biography) return <div>Loading biography...</div>;
  
  return (
    <div className="biography-card">
      <h2>Personal Biography</h2>
      
      <section>
        <h3>Identity</h3>
        <p>{biography.identitySummary}</p>
        <div className="tags">
          {biography.identityCore.map(tag => (
            <span key={tag} className="tag">{tag}</span>
          ))}
        </div>
      </section>
      
      <section>
        <h3>Core Values</h3>
        <ul>
          {biography.coreValues.map(v => (
            <li key={v.value}>{v.value} ({v.score.toFixed(2)})</li>
          ))}
        </ul>
      </section>
      
      <section>
        <h3>Life Narrative</h3>
        <p>{biography.narrativeFirstPerson}</p>
      </section>
      
      <div className="metadata">
        Version: {biography.version} | Quality: {biography.qualityScore.toFixed(2)}
      </div>
    </div>
  );
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. å‘é‡ç›¸ä¼¼åº¦æœç´¢åŠ é€Ÿ

```bash
# å®‰è£…sqlite-vssæ‰©å±•
pip3 install sqlite-vss

# æˆ–ä½¿ç”¨ChromaDB
pip3 install chromadb
```

**ä¿®æ”¹**: `hierarchical_memory_manager.py`

```python
import chromadb

class L0MemoryManager:
    def __init__(self, db_path):
        self.db_path = db_path
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.create_collection("memories")
    
    def retrieve_memories(self, user_id, query, limit=20):
        # å‘é‡æœç´¢
        query_embedding = self._generate_embedding(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=limit,
            where={"user_id": user_id}
        )
        return results
```

### 2. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import redis

# Redisç¼“å­˜
redis_client = redis.Redis(host='localhost', port=6379, db=0)

@lru_cache(maxsize=100)
def get_cached_biography(user_id):
    cached = redis_client.get(f"bio:{user_id}")
    if cached:
        return json.loads(cached)
    
    bio = fetch_biography_from_db(user_id)
    redis_client.setex(f"bio:{user_id}", 3600, json.dumps(bio))
    return bio
```

### 3. å¼‚æ­¥èšç±»

```typescript
// åå°ä»»åŠ¡é˜Ÿåˆ—
import Bull from 'bull';

const clusteringQueue = new Bull('clustering', {
  redis: { host: 'localhost', port: 6379 }
});

clusteringQueue.process(async (job) => {
  const { userId } = job.data;
  await memoryV2Service.runClustering(userId);
});

// æ·»åŠ ä»»åŠ¡
clusteringQueue.add({ userId: 'user123' }, { delay: 60000 });
```

---

## ç›‘æ§æŒ‡æ ‡

### Grafana Dashboardé…ç½®

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'personality_v2'
    static_configs:
      - targets: ['localhost:3001']
```

**å…³é”®æŒ‡æ ‡**:

1. **Alignment Score**
   - Linguistic: > 0.95
   - Emotional: > 0.92
   - Value: > 0.95
   - Factual: > 0.98

2. **Generation Performance**
   - Latency: < 2.0s (P95)
   - Throughput: > 10 req/s

3. **Memory Quality**
   - L1 Cluster Count: 10-50 per user
   - L2 Quality Score: > 0.8
   - L0 Memory Retention: 100%

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. "No module named 'sentence_transformers'"

```bash
pip3 install sentence-transformers
```

#### 2. "HDBSCAN clustering failed"

åŸå› : è®°å¿†æ•°é‡ä¸è¶³ (<30æ¡)

```python
# é™ä½min_cluster_size
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=5,  # ä»10é™åˆ°5
    min_samples=2        # ä»3é™åˆ°2
)
```

#### 3. "Biography quality_score < 0.5"

åŸå› : èšç±»è´¨é‡ä½ or LLMç”Ÿæˆå¤±è´¥

```python
# æ£€æŸ¥èšç±»
clusters = l1_manager.get_clusters(user_id)
print(f"Cluster count: {len(clusters)}")

# æ£€æŸ¥LLMå“åº”
result = llm_generate("Test prompt")
print(f"LLM response: {result}")
```

#### 4. "Alignment score stuck at 0.5"

åŸå› : L2ä¼ è®°ä¸å­˜åœ¨

```bash
# é‡æ–°ç”Ÿæˆä¼ è®°
python3 src/ml/hierarchical_memory_manager.py \
  --db-path ./self_agent.db \
  --user-id USER_ID \
  --action biography
```

---

## éªŒæ”¶æ ‡å‡†

### V2.0ä¸Šçº¿è¦æ±‚

- [x] æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ (13 tables)
- [x] Pythonä¾èµ–å®‰è£…å®Œæˆ
- [ ] LLMé›†æˆå®Œæˆ (Gemini API)
- [ ] APIç«¯ç‚¹å…¨éƒ¨é€šè¿‡æµ‹è¯• (15 endpoints)
- [ ] è‡³å°‘1ä¸ªç”¨æˆ·å®ŒæˆL0â†’L1â†’L2ç®¡çº¿
- [ ] Turing Test Pass Rate > 95%
- [ ] å‰ç«¯UI: è‡³å°‘3ä¸ªå¯è§†åŒ–ç»„ä»¶
- [ ] ç›‘æ§æŒ‡æ ‡é…ç½®å®Œæˆ

### æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | V1.0 | V2.0 (ç›®æ ‡) |
|-----|------|-------------|
| å›¾çµæµ‹è¯•é€šè¿‡ç‡ | 65-70% | **95%+** |
| è¯­è¨€ä¸€è‡´æ€§ | 70% | **95%** |
| æƒ…æ„Ÿå‡†ç¡®æ€§ | 65% | **92%** |
| ä»·å€¼è§‚åŒ¹é… | 60% | **95%** |
| äº‹å®å‡†ç¡®æ€§ | 80% | **98%** |
| å“åº”å»¶è¿Ÿ (P95) | <1.0s | <2.0s |

---

## ä¸‹ä¸€æ­¥è®¡åˆ’

### Week 7-8: é«˜çº§åŠŸèƒ½

1. **å¤šæ¨¡æ€è®°å¿†**
   - å›¾ç‰‡è®°å¿† (CLIP embeddings)
   - è¯­éŸ³è®°å¿† (Whisper transcription)
   - è§†é¢‘è®°å¿† (frame sampling)

2. **è”é‚¦å­¦ä¹ **
   - è®¾å¤‡ç«¯æ¨¡å‹è®­ç»ƒ
   - å·®åˆ†éšç§ä¿æŠ¤
   - æ¨¡å‹èšåˆ

3. **å®æ—¶åŒæ­¥**
   - WebSocketæ¨é€
   - å¢é‡æ›´æ–°
   - å†²çªè§£å†³

---

## å‚è€ƒèµ„æ–™

- [Second-Me GitHub](https://github.com/mindverse/Second-Me) - 14.4k stars
- [AI-Native Memory Paper](https://arxiv.org/pdf/2503.08102) - ç†è®ºåŸºç¡€
- [HDBSCAN Documentation](https://hdbscan.readthedocs.io/) - èšç±»ç®—æ³•
- [Sentence-Transformers](https://www.sbert.net/) - å‘é‡åµŒå…¥

---

**ç‰ˆæœ¬å†å²**:
- 2.0.0 (2025-01-XX): AI-Native Memoryæ¶æ„ (HMM + Me-Alignment)
- 1.0.0 (2025-01-XX): Feature-basedæ¶æ„ (65-70% pass rate)
